{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bzeng18/AIPI531/blob/main/Homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihKovSjySlVg",
        "outputId": "515de83b-a28d-41ad-b264-cba9557dafe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/SA2C_code/Kaggle\n",
            "archive-2\t     one_hot_encoded.csv   replay_buffer.py\t       SNQN1.py\t\t test.py\n",
            "data\t\t     pop.py\t\t   report_SNQN_FeatureVec.txt  SNQN_features.py  utility.py\n",
            "DQN_NS.py\t     preprocess_kaggle.py  SA2C.py\t\t       SNQN.py\n",
            "NextItNetModules.py  __pycache__\t   SASRecModules.py\t       split_data.py\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "PROJ_DIR = '/content/drive/MyDrive/Colab Notebooks/SA2C_code/Kaggle'\n",
        "# change current directory after mounting\n",
        "%cd $PROJ_DIR\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvIEFEEaXlyQ",
        "outputId": "a8877fce-edf2-4fef-a34b-16db436cfacf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install pandas trfl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLdlcVbMWLtn",
        "outputId": "a6a59c96-e51a-4753-9bdb-58974634aa77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-24 03:41:59.216381: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-24 03:41:59.216434: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-24 03:41:59.216468: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-24 03:41:59.241268: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-24 03:42:01.253320: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "/content/drive/MyDrive/Colab Notebooks/SA2C_code/Kaggle/SNQN1.py:80: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Colab Notebooks/SA2C_code/Kaggle/SNQN1.py:79: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "/content/drive/MyDrive/Colab Notebooks/SA2C_code/Kaggle/SNQN1.py:207: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(\n",
            "/content/drive/MyDrive/Colab Notebooks/SA2C_code/Kaggle/SNQN1.py:211: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(\n",
            "2023-11-24 03:42:15.318822: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 03:42:15.822499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 03:42:15.822832: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 03:42:15.823605: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 03:42:15.823872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 03:42:15.824063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 03:42:18.237311: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 03:42:18.237573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 03:42:18.237716: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-24 03:42:18.237804: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 03:42:18.237939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-11-24 03:42:18.265266: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.600000\n",
            "clicks hr ndcg @ 5 : 0.000068, 0.000040\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.400000\n",
            "clicks hr ndcg @ 10 : 0.000101, 0.000052\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 5.200000\n",
            "clicks hr ndcg @ 15 : 0.000220, 0.000083\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 6.800000\n",
            "clicks hr ndcg @ 20 : 0.000287, 0.000099\n",
            "purchase hr and ndcg @20 : 0.000000, 0.000000\n",
            "#############################################################\n",
            "the loss in 200th batch is: 10.959256\n",
            "the loss in 400th batch is: 10.652143\n",
            "the loss in 600th batch is: 10.659745\n",
            "the loss in 800th batch is: 10.408484\n",
            "the loss in 1000th batch is: 10.213929\n",
            "the loss in 1200th batch is: 9.911634\n",
            "the loss in 1400th batch is: 9.992554\n",
            "the loss in 1600th batch is: 9.881994\n",
            "the loss in 1800th batch is: 9.800384\n",
            "the loss in 2000th batch is: 9.517220\n",
            "the loss in 2200th batch is: 9.413046\n",
            "the loss in 2400th batch is: 9.552279\n",
            "the loss in 2600th batch is: 9.348905\n",
            "the loss in 2800th batch is: 9.086817\n",
            "the loss in 3000th batch is: 8.897791\n",
            "the loss in 3200th batch is: 8.885805\n",
            "the loss in 3400th batch is: 9.002219\n",
            "the loss in 3600th batch is: 8.845339\n",
            "the loss in 3800th batch is: 8.437706\n",
            "the loss in 4000th batch is: 8.834316\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6028.200000\n",
            "clicks hr ndcg @ 5 : 0.172738, 0.137070\n",
            "purchase hr and ndcg @5 : 0.366849, 0.315062\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 6950.800000\n",
            "clicks hr ndcg @ 10 : 0.203616, 0.147096\n",
            "purchase hr and ndcg @10 : 0.403137, 0.326918\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7472.400000\n",
            "clicks hr ndcg @ 15 : 0.221477, 0.151829\n",
            "purchase hr and ndcg @15 : 0.421848, 0.331890\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7839.800000\n",
            "clicks hr ndcg @ 20 : 0.234384, 0.154877\n",
            "purchase hr and ndcg @20 : 0.433566, 0.334675\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.671950\n",
            "the loss in 4400th batch is: 8.119563\n",
            "the loss in 4600th batch is: 8.497609\n",
            "the loss in 4800th batch is: 8.293962\n",
            "the loss in 5000th batch is: 7.916663\n",
            "the loss in 5200th batch is: 7.821383\n",
            "the loss in 5400th batch is: 8.190278\n",
            "the loss in 5600th batch is: 7.970415\n",
            "the loss in 5800th batch is: 7.990067\n",
            "the loss in 6000th batch is: 7.575842\n",
            "the loss in 6200th batch is: 8.186205\n",
            "the loss in 6400th batch is: 7.693991\n",
            "the loss in 6600th batch is: 7.633515\n",
            "the loss in 6800th batch is: 6.925353\n",
            "the loss in 7000th batch is: 7.499478\n",
            "the loss in 7200th batch is: 7.154807\n",
            "the loss in 7400th batch is: 7.389869\n",
            "the loss in 7600th batch is: 7.142375\n",
            "the loss in 7800th batch is: 6.855408\n",
            "the loss in 8000th batch is: 7.126947\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8039.800000\n",
            "clicks hr ndcg @ 5 : 0.232778, 0.183507\n",
            "purchase hr and ndcg @5 : 0.478548, 0.407292\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 9252.000000\n",
            "clicks hr ndcg @ 10 : 0.275895, 0.197491\n",
            "purchase hr and ndcg @10 : 0.514837, 0.418994\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9932.200000\n",
            "clicks hr ndcg @ 15 : 0.299402, 0.203714\n",
            "purchase hr and ndcg @15 : 0.538273, 0.425173\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 10394.600000\n",
            "clicks hr ndcg @ 20 : 0.315267, 0.207466\n",
            "purchase hr and ndcg @20 : 0.554716, 0.429025\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 6.769033\n",
            "the loss in 8400th batch is: 7.213889\n",
            "the loss in 8600th batch is: 7.178213\n",
            "the loss in 8800th batch is: 6.802748\n",
            "the loss in 9000th batch is: 6.793930\n",
            "the loss in 9200th batch is: 6.558827\n",
            "the loss in 9400th batch is: 7.114015\n",
            "the loss in 9600th batch is: 6.462533\n",
            "the loss in 9800th batch is: 6.810575\n",
            "the loss in 10000th batch is: 7.149433\n",
            "the loss in 10200th batch is: 7.071388\n",
            "the loss in 10400th batch is: 6.258438\n",
            "the loss in 10600th batch is: 6.381994\n",
            "the loss in 10800th batch is: 6.792321\n",
            "the loss in 11000th batch is: 6.566554\n",
            "the loss in 11200th batch is: 6.563134\n",
            "the loss in 11400th batch is: 6.739915\n",
            "the loss in 11600th batch is: 6.245431\n",
            "the loss in 11800th batch is: 6.633999\n",
            "the loss in 12000th batch is: 6.026123\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8700.000000\n",
            "clicks hr ndcg @ 5 : 0.252523, 0.198359\n",
            "purchase hr and ndcg @5 : 0.515026, 0.434986\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 10054.800000\n",
            "clicks hr ndcg @ 10 : 0.300019, 0.213767\n",
            "purchase hr and ndcg @10 : 0.558685, 0.449036\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 10815.400000\n",
            "clicks hr ndcg @ 15 : 0.326289, 0.220725\n",
            "purchase hr and ndcg @15 : 0.584956, 0.456026\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 11315.600000\n",
            "clicks hr ndcg @ 20 : 0.344006, 0.224911\n",
            "purchase hr and ndcg @20 : 0.600265, 0.459656\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 6.404324\n",
            "the loss in 12400th batch is: 6.585335\n",
            "the loss in 12600th batch is: 6.086530\n",
            "the loss in 12800th batch is: 6.140863\n",
            "the loss in 13000th batch is: 6.326870\n",
            "the loss in 13200th batch is: 6.522470\n",
            "the loss in 13400th batch is: 5.977585\n",
            "the loss in 13600th batch is: 6.186574\n",
            "the loss in 13800th batch is: 6.537784\n",
            "the loss in 14000th batch is: 5.771166\n",
            "the loss in 14200th batch is: 6.085927\n",
            "the loss in 14400th batch is: 6.198512\n",
            "the loss in 14600th batch is: 6.502931\n",
            "the loss in 14800th batch is: 6.331312\n",
            "the loss in 15000th batch is: 6.205812\n",
            "the loss in 15200th batch is: 6.305237\n",
            "the loss in 15400th batch is: 5.840114\n",
            "the loss in 15600th batch is: 6.016375\n",
            "the loss in 15800th batch is: 6.232392\n",
            "the loss in 16000th batch is: 5.593010\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8948.600000\n",
            "clicks hr ndcg @ 5 : 0.260367, 0.203107\n",
            "purchase hr and ndcg @5 : 0.526933, 0.442854\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 10370.600000\n",
            "clicks hr ndcg @ 10 : 0.310491, 0.219346\n",
            "purchase hr and ndcg @10 : 0.571537, 0.457284\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 11126.400000\n",
            "clicks hr ndcg @ 15 : 0.337447, 0.226488\n",
            "purchase hr and ndcg @15 : 0.593839, 0.463235\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 11658.200000\n",
            "clicks hr ndcg @ 20 : 0.356542, 0.230997\n",
            "purchase hr and ndcg @20 : 0.608959, 0.466817\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 5.720684\n",
            "the loss in 16400th batch is: 5.720809\n",
            "the loss in 16600th batch is: 6.185657\n",
            "the loss in 16800th batch is: 6.327065\n",
            "the loss in 17000th batch is: 5.541329\n",
            "the loss in 17200th batch is: 5.478128\n",
            "the loss in 17400th batch is: 5.814694\n",
            "the loss in 17600th batch is: 5.747300\n",
            "the loss in 17800th batch is: 5.831729\n",
            "the loss in 18000th batch is: 6.131204\n",
            "the loss in 18200th batch is: 5.716735\n",
            "the loss in 18400th batch is: 6.051951\n",
            "the loss in 18600th batch is: 5.832894\n",
            "the loss in 18800th batch is: 5.640716\n",
            "the loss in 19000th batch is: 5.744232\n",
            "the loss in 19200th batch is: 5.879986\n"
          ]
        }
      ],
      "source": [
        "#without item features\n",
        "! python SNQN1.py --model=GRU --epoch=5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "item_features1 = pd.read_csv(\"./archive-2/item_properties_part1.csv\")\n",
        "item_features2 = pd.read_csv(\"./archive-2/item_properties_part2.csv\")\n",
        "sorted_events = pd.read_csv(\"./data/sorted_events.csv\")\n",
        "item_features = pd.concat(\n",
        "            [item_features1, item_features2],\n",
        "            ignore_index=True,\n",
        "        )\n",
        "item_features = item_features[item_features['property']!=\"available\"]\n",
        "item_features = item_features[item_features[\"itemid\"].isin(sorted_events[\"item_id\"].unique())]\n",
        "filtered_df = item_features.groupby(['itemid', 'property']).filter(lambda x: x['value'].nunique() == 1)\n",
        "df = filtered_df\n",
        "df['property_value'] = df['property'].astype(str) + \"_\" + df['value'].astype(str)\n",
        "top_1000_properties = df['property_value'].value_counts().head(300).index\n",
        "df2 = df[df['property_value'].isin(top_1000_properties)]\n",
        "one_hot_encoded = df2.pivot_table(index='itemid',\n",
        "                                          columns='property_value',\n",
        "                                          aggfunc=len,\n",
        "                                          fill_value=0)\n",
        "one_hot_encoded.columns = one_hot_encoded.columns.get_level_values(1)\n",
        "all_itemids = sorted_events[\"item_id\"].drop_duplicates()\n",
        "one_hot_encoded_full = pd.DataFrame({'itemid': all_itemids}).merge(one_hot_encoded,\n",
        "                                                                  on='itemid',\n",
        "                                                                  how='left').fillna(0)\n",
        "\n",
        "one_hot_encoded_full.iloc[:, 1:] = one_hot_encoded_full.iloc[:, 1:].astype(int)\n",
        "one_hot_encoded_full.set_index('itemid', inplace=True)\n",
        "one_hot_encoded_full.to_csv('one_hot_encoded.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvnEuM4Qb2nO",
        "outputId": "75b313d5-de54-4d38-e59f-1bf1225e9606"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-156f7c064e98>:26: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  one_hot_encoded_full.iloc[:, 1:] = one_hot_encoded_full.iloc[:, 1:].astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHfl8OuS6GHo",
        "outputId": "f34cd502-4757-4915-f103-ca22e7d4e792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-24 17:59:00.827490: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-24 17:59:00.827542: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-24 17:59:00.827576: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-24 17:59:00.835102: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-24 17:59:01.945894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "/content/drive/MyDrive/Colab Notebooks/SA2C_code/Kaggle/SNQN_features.py:82: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Colab Notebooks/SA2C_code/Kaggle/SNQN_features.py:81: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "/content/drive/MyDrive/Colab Notebooks/SA2C_code/Kaggle/SNQN_features.py:209: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(\n",
            "/content/drive/MyDrive/Colab Notebooks/SA2C_code/Kaggle/SNQN_features.py:213: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2 = tf.compat.v1.layers.dense(\n",
            "/content/drive/MyDrive/Colab Notebooks/SA2C_code/Kaggle/SNQN_features.py:217: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.w_item = tf.compat.v1.layers.dense(\n",
            "2023-11-24 17:59:21.409403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 17:59:21.496628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 17:59:21.496982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 17:59:21.497805: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 17:59:21.498057: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 17:59:21.498275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 17:59:22.163515: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 17:59:22.163792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 17:59:22.163921: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-24 17:59:22.164013: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 17:59:22.164171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-11-24 17:59:23.193868: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.400000\n",
            "clicks hr ndcg @ 5 : 0.000059, 0.000046\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 2.600000\n",
            "clicks hr ndcg @ 10 : 0.000110, 0.000064\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 3.600000\n",
            "clicks hr ndcg @ 15 : 0.000152, 0.000075\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 5.000000\n",
            "clicks hr ndcg @ 20 : 0.000211, 0.000089\n",
            "purchase hr and ndcg @20 : 0.000000, 0.000000\n",
            "#############################################################\n",
            "the loss in 200th batch is: 10.794866\n",
            "the loss in 400th batch is: 10.494131\n",
            "the loss in 600th batch is: 10.521468\n",
            "the loss in 800th batch is: 10.203328\n",
            "the loss in 1000th batch is: 9.924219\n",
            "the loss in 1200th batch is: 10.222154\n",
            "the loss in 1400th batch is: 10.162626\n",
            "the loss in 1600th batch is: 9.884591\n",
            "the loss in 1800th batch is: 9.990739\n",
            "the loss in 2000th batch is: 9.634135\n",
            "the loss in 2200th batch is: 9.486740\n",
            "the loss in 2400th batch is: 9.239555\n",
            "the loss in 2600th batch is: 9.072561\n",
            "the loss in 2800th batch is: 8.881234\n",
            "the loss in 3000th batch is: 9.402583\n",
            "the loss in 3200th batch is: 9.303873\n",
            "the loss in 3400th batch is: 8.997558\n",
            "the loss in 3600th batch is: 8.625725\n",
            "the loss in 3800th batch is: 8.388680\n",
            "the loss in 4000th batch is: 8.306735\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 4185.000000\n",
            "clicks hr ndcg @ 5 : 0.119774, 0.090290\n",
            "purchase hr and ndcg @5 : 0.255339, 0.203393\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 5136.800000\n",
            "clicks hr ndcg @ 10 : 0.149392, 0.099900\n",
            "purchase hr and ndcg @10 : 0.302778, 0.218751\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 5672.400000\n",
            "clicks hr ndcg @ 15 : 0.166703, 0.104480\n",
            "purchase hr and ndcg @15 : 0.326592, 0.225047\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 6049.600000\n",
            "clicks hr ndcg @ 20 : 0.178841, 0.107342\n",
            "purchase hr and ndcg @20 : 0.343602, 0.229058\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.570914\n",
            "the loss in 4400th batch is: 8.439850\n",
            "the loss in 4600th batch is: 8.277075\n",
            "the loss in 4800th batch is: 7.914330\n",
            "the loss in 5000th batch is: 7.982716\n",
            "the loss in 5200th batch is: 8.452906\n",
            "the loss in 5400th batch is: 7.479079\n",
            "the loss in 5600th batch is: 8.287431\n",
            "the loss in 5800th batch is: 8.188118\n",
            "the loss in 6000th batch is: 7.944645\n",
            "the loss in 6200th batch is: 7.601926\n",
            "the loss in 6400th batch is: 7.627024\n",
            "the loss in 6600th batch is: 7.640701\n",
            "the loss in 6800th batch is: 7.678001\n",
            "the loss in 7000th batch is: 7.874657\n",
            "the loss in 7200th batch is: 7.547015\n",
            "the loss in 7400th batch is: 7.538544\n",
            "the loss in 7600th batch is: 7.236664\n",
            "the loss in 7800th batch is: 7.074984\n",
            "the loss in 8000th batch is: 7.337028\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 5983.600000\n",
            "clicks hr ndcg @ 5 : 0.173516, 0.130104\n",
            "purchase hr and ndcg @5 : 0.354942, 0.279522\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 7323.600000\n",
            "clicks hr ndcg @ 10 : 0.216287, 0.143959\n",
            "purchase hr and ndcg @10 : 0.416934, 0.299712\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8103.400000\n",
            "clicks hr ndcg @ 15 : 0.241383, 0.150601\n",
            "purchase hr and ndcg @15 : 0.452088, 0.309022\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 8622.200000\n",
            "clicks hr ndcg @ 20 : 0.259251, 0.154824\n",
            "purchase hr and ndcg @20 : 0.470232, 0.313312\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 6.955360\n",
            "the loss in 8400th batch is: 7.104152\n",
            "the loss in 8600th batch is: 7.398501\n",
            "the loss in 8800th batch is: 7.202891\n",
            "the loss in 9000th batch is: 7.049312\n",
            "the loss in 9200th batch is: 7.048411\n",
            "the loss in 9400th batch is: 7.019263\n",
            "the loss in 9600th batch is: 6.841408\n",
            "the loss in 9800th batch is: 6.882286\n",
            "the loss in 10000th batch is: 6.798790\n",
            "the loss in 10200th batch is: 6.859854\n",
            "the loss in 10400th batch is: 6.769145\n",
            "the loss in 10600th batch is: 6.534512\n",
            "the loss in 10800th batch is: 6.815571\n",
            "the loss in 11000th batch is: 6.770587\n",
            "the loss in 11200th batch is: 7.073915\n",
            "the loss in 11400th batch is: 6.649273\n",
            "the loss in 11600th batch is: 7.147773\n",
            "the loss in 11800th batch is: 6.772611\n",
            "the loss in 12000th batch is: 6.474001\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6495.800000\n",
            "clicks hr ndcg @ 5 : 0.189120, 0.142119\n",
            "purchase hr and ndcg @5 : 0.381969, 0.299003\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8031.800000\n",
            "clicks hr ndcg @ 10 : 0.238526, 0.158078\n",
            "purchase hr and ndcg @10 : 0.451332, 0.321445\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8906.800000\n",
            "clicks hr ndcg @ 15 : 0.267476, 0.165746\n",
            "purchase hr and ndcg @15 : 0.487242, 0.331009\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9462.600000\n",
            "clicks hr ndcg @ 20 : 0.286824, 0.170317\n",
            "purchase hr and ndcg @20 : 0.505765, 0.335393\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 6.420090\n",
            "the loss in 12400th batch is: 6.621805\n",
            "the loss in 12600th batch is: 6.015074\n",
            "the loss in 12800th batch is: 6.585900\n",
            "the loss in 13000th batch is: 6.326642\n",
            "the loss in 13200th batch is: 6.335829\n",
            "the loss in 13400th batch is: 6.335747\n",
            "the loss in 13600th batch is: 6.620900\n",
            "the loss in 13800th batch is: 6.388175\n",
            "the loss in 14000th batch is: 6.360108\n",
            "the loss in 14200th batch is: 6.035271\n",
            "the loss in 14400th batch is: 6.309564\n",
            "the loss in 14600th batch is: 6.137797\n",
            "the loss in 14800th batch is: 6.396591\n",
            "the loss in 15000th batch is: 6.194457\n",
            "the loss in 15200th batch is: 6.305959\n",
            "the loss in 15400th batch is: 6.061289\n",
            "the loss in 15600th batch is: 6.013634\n",
            "the loss in 15800th batch is: 5.522401\n",
            "the loss in 16000th batch is: 6.495463\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6750.200000\n",
            "clicks hr ndcg @ 5 : 0.197167, 0.146082\n",
            "purchase hr and ndcg @5 : 0.394065, 0.308342\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8312.000000\n",
            "clicks hr ndcg @ 10 : 0.248846, 0.162775\n",
            "purchase hr and ndcg @10 : 0.458136, 0.329037\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9262.000000\n",
            "clicks hr ndcg @ 15 : 0.279614, 0.170921\n",
            "purchase hr and ndcg @15 : 0.500095, 0.340109\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9879.000000\n",
            "clicks hr ndcg @ 20 : 0.300196, 0.175784\n",
            "purchase hr and ndcg @20 : 0.524665, 0.345921\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 6.441034\n",
            "the loss in 16400th batch is: 5.924209\n",
            "the loss in 16600th batch is: 6.012460\n",
            "the loss in 16800th batch is: 6.154296\n",
            "the loss in 17000th batch is: 5.721831\n",
            "the loss in 17200th batch is: 5.858434\n",
            "the loss in 17400th batch is: 6.084251\n",
            "the loss in 17600th batch is: 6.307351\n",
            "the loss in 17800th batch is: 6.092216\n",
            "the loss in 18000th batch is: 5.501641\n",
            "the loss in 18200th batch is: 6.098415\n",
            "the loss in 18400th batch is: 6.186314\n",
            "the loss in 18600th batch is: 6.087519\n",
            "the loss in 18800th batch is: 6.065722\n",
            "the loss in 19000th batch is: 5.588136\n",
            "the loss in 19200th batch is: 5.612119\n"
          ]
        }
      ],
      "source": [
        "#With item features\n",
        "! python SNQN_features.py --model=GRU --epoch=5"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGR3d20Z8a0nabDVBL3ovv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}